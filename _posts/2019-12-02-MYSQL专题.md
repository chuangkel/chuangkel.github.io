---
layout:     post
title:	MYSQL专题
subtitle: 	
date:       2019-12-02
author:     chuangkel
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 数据库
---

#  逻辑架构

**引言**

1. 为什么要同步redo log而不是保持数据直接修改的同步？即redo log同步来出现脏数据时进行重做 vs 数据修改直接持久化到磁盘 两个的代价前者要低一点，为什么呢？ 为什么要这么设计呢？
2. 多版本控制会引发不可重复读的问题吗？ 
3. redo log日志在事务未提交前就已经开始把redo log持久化到磁盘，如果事务回滚了会发生什么？
4. update test_table set close = 100 where name = 1 如果name不是索引列的话，此更新会使用行锁还是表锁？
5. Checkpoint的作用？
6. select lock in share mode 和 select的区别？
7. mysql各引擎自己的区别?
8. 为什么能实现引擎的组件化？
9. innodb下的线程？
10. innodb下的缓冲池？
11. innodb下的页？

**分析**
1. 为什么要同步redo log而不是保持数据直接修改的同步？即redo log同步来出现脏数据时进行重做 vs 数据修改直接持久化到磁盘 两个的代价前者要低一点，为什么呢？ 为什么要这么设计呢？



2. 多版本控制会引发不可重复读的问题吗？ 

不可重复读的定义： 同一个事物两次查询同一行或相同的几行记录，前后两次查询的行内数据不一致。  多版本控制下，写的事务会新增一个版本，读的事务读的是在此之前最新的版本。 那么在一个事务当中两次读的间隔时间之内 如果有写事务提交了版本，此时最新的版本号改变，那么读事务的第二次读的行内数据和第一次读的行内数据就可能不一致了。 

在默认隔离级别可重复读下，行的读取加了gap lock吗？ 若在查询的范围之间加锁，确实可以到达可重复读的效果。事实是这样的吗

锁和多版本控制是怎么协调的？多版本是将需要写的版本拷贝一份作为一个版本，但是未提交前这个版本并不会被其他事务读到。

一个事务两次查询，读取的可以是两个版本吗？



3. redo log日志在事务未提交前就已经开始把redo log持久化到磁盘，如果事务回滚了会发生什么？



4. update test_table set close = 100 where name = 1 如果name不是索引列的话，此更新会使用行锁还是表锁？



5. Checkpoint的作用？

master thread 定期执行checkpoint将脏页刷回磁盘
页空间不够用时，根据页淘汰LRU算法执行checkpoint将脏页刷回磁盘
async/sync执行
redo log 不可用时

6. innodb下的线程？

1. master thread: 是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证了数据 的一致性，包括脏页的刷新，合并插入缓冲（insert buffer)，undo页的回收。
2. io thread: 在innodb引擎中使用了大量的async io (AIO) 来处理写io请求，这样极大地提高了数据库的性能，而io thread 的工作主要是负责这些io请求的回调（call back)处理。共有四种io thread, 分别是read、write、redo/undo log io thread、insert buffer thread 。
3. purge thread: 事务提交之后，所使用的undo log日志不再需要，因此需要purge thread 来回收已经分配并使用的undo log页。通过以下配置文件在启动时启动purge thread。

```mysql
[mysqld]
innodb_purge_threads=1
```

4. page cleaner thread:  page cleaner thread 是innodb 1.2.x版本中引入的，作用是将脏页刷回磁盘，其实就是master thread的将脏页刷回磁盘的工作全部交给page cleaner thread来处理，提高了innodb存储引擎的性能。

7. innodb下的缓冲池？



8. innodb下的页？


### 正文

- 连接器层 
  - 功能：连接处理，授权认证，安全
- 服务器层
  - 查询缓存
  - 解析器
  - 优化器
  - 执行器
  - binlog日志
- 存储引擎层
  - InnoDB
  - MyISAM
  - Memory



* 基于行的复制



* 基于语句的复制



* 异步复制

![img](/../img/数据库异步复制.png)



* 半同步复制

![img](/../img/数据半同步复制.png)



复制过程中的线程

* 主库开启dump thread复制响应从库IO thread请求

* 从库开启IO thread，负责连接主库，请求binlog,将binlog写入relay-log(中继日志)
* 从库开启 Sql thread，负责执行relay-log事件



#### bin log和redo log及undo log的区别？

> bin log 先于redo log产生，可以在my.cnf配置文件中配置相关参数

* bin log
  * 在服务层产生，针对大多数存储引擎
  * 全量拷贝，事务所有的操作。T事务增加一行row，然后删除row，会记录下操作过程。
  * sync_binlog参数：控制bin log 同步到磁盘的频率
  * sync_binlog默认值0，不主动同步
  * sync_binlog值为1，每写一次bin log 同步一次磁盘，最安全
  
* redo log（事务提交到内存，所以需要redo log日志持久化到磁盘，掉电之后进行数据的恢复）
  * 在存储引擎层，是innodb产生的
  * 事务终态拷贝，具有幂等性（同一个数据操作？），T事务增加一行row，然后删除row，相当于记录不会修改。
  * redo log包括内存缓冲日志（redo log buffer）、磁盘持久化日志（redo log file）两部分。内存缓冲日志持久化到磁盘通过参数innodb_flush_log_at_trx_commit 来控制
    * innodb_flush_log_at_trx_commit 为1，事务提交立刻提交redo log buffer 到 os buffer，并且调用fsync()函数，将os buffer提交到磁盘。（数据安全，耗时较长）
    * innodb_flush_log_at_trx_commit 为0，每秒钟提交redo log buffer 到 os buffer，并且调用fsync()函数，将os buffer提交到磁盘。（数据较不安全，耗时较短）
    * innodb_flush_log_at_trx_commit 为2，事务提交立刻提交redo log buffer 到 os buffer，并且每秒调用fsync()函数，将os buffer提交到磁盘。（数据较不安全，耗时较短，可以防止mysqld 进程崩溃造成的数据丢失）
  
  * fsync()系统调用，将内核缓存提交到磁盘

![img](/../img/fsync用户空间到内核空间)

* undo log

  > undo log提供回滚和多个行版本控制(MVCC)，事务失败回滚时，会借助undo log进行回滚。
  >
  > * 回滚：undo log 是逻辑日志（redo log 是物理日志），undo log 会记录相反的操作（delete 一条记录会产生一条insert记录的日志，update会产生一条相反的update日志）。
  >
  > * 多个行版本控制(MVCC)：某一行被锁定而需要读取时，从undo log日志中解析出上一个版本记录的数据，实现非锁定一致性读取。



### MySQL-LSN

查看lsn:
   show engine innodb status

   Log sequence number 2687274848548 
   Log flushed up to 2687274848516
   Pages flushed up to 2687273963960
   Last checkpoint at 2687273963960

   1 简单说明

   Log sequence number: 当前系统最大的LSN号
   log flushed up to:当前已经写入redo日志文件的LSN
   pages flushed up to：已经将更改写入脏页的lsn号
   Last checkpoint at就是系统最后一次刷新buffer pool脏中页数据到磁盘的checkpoint
   2 以上4个LSN是递减的，即： LSN1>=LSN2>=LSN3>=LSN4.
   3 内容

​     每个数据页有LSN，重做日志有LSN，checkpoint有LSN。

  4 定义说明
    1 LSN（log sequence number）日志序列号，5.6.3之后占用8字节，LSN主要用于发生crash时对数据进行recovery，LSN是一个一直递增的整型数字，表示事务写入到日志的字节总量。
     LSN不仅只存在于重做日志中，在每个数据页头部也会有对应的LSN号，该LSN记录当前页最后一次修改的LSN号，用于在recovery时对比重做日志LSN号决定是否对该页进行恢复数据。前面说的checkpoint也是有LSN号记录的，LSN号串联起一个事务开始到恢复的过程。

例子：  show engine innodb status

```
| InnoDB |      |
=====================================
191008 10:23:24 INNODB MONITOR OUTPUT
=====================================
Per second averages calculated from the last 58 seconds
-----------------
BACKGROUND THREAD
-----------------
srv_master_thread loops: 68 1_second, 68 sleeps, 5 10_second, 20 background, 20 flush
srv_master_thread log flush and writes: 68
----------
SEMAPHORES
----------
OS WAIT ARRAY INFO: reservation count 8, signal count 8
Mutex spin waits 7, rounds 72, OS waits 2
RW-shared spins 6, rounds 180, OS waits 6
RW-excl spins 0, rounds 0, OS waits 0
Spin rounds per wait: 10.29 mutex, 30.00 RW-shared, 0.00 RW-excl
------------
TRANSACTIONS
------------
Trx id counter 340C
Purge done for trx's n:o < 3405 undo n:o < 0
History list length 243
LIST OF TRANSACTIONS FOR EACH SESSION:
---TRANSACTION 0, not started
MySQL thread id 14, OS thread handle 0x1478, query id 252 localhost 127.0.0.1 ODBC
show engine innodb status
--------
FILE I/O
--------
I/O thread 0 state: wait Windows aio (insert buffer thread)
I/O thread 1 state: wait Windows aio (log thread)
I/O thread 2 state: wait Windows aio (read thread)
I/O thread 3 state: wait Windows aio (read thread)
I/O thread 4 state: wait Windows aio (read thread)
I/O thread 5 state: wait Windows aio (read thread)
I/O thread 6 state: wait Windows aio (write thread)
I/O thread 7 state: wait Windows aio (write thread)
I/O thread 8 state: wait Windows aio (write thread)
I/O thread 9 state: wait Windows aio (write thread)
Pending normal aio reads: 0 [0, 0, 0, 0] , aio writes: 0 [0, 0, 0, 0] ,
 ibuf aio reads: 0, log i/o's: 0, sync i/o's: 0
Pending flushes (fsync) log: 0; buffer pool: 0
536 OS file reads, 38 OS file writes, 24 OS fsyncs
0.00 reads/s, 0 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s
-------------------------------------
INSERT BUFFER AND ADAPTIVE HASH INDEX
-------------------------------------
Ibuf: size 1, free list len 0, seg size 2, 0 merges
merged operations:
 insert 0, delete mark 0, delete 0
discarded operations:
 insert 0, delete mark 0, delete 0
Hash table size 276707, node heap has 1 buffer(s)
0.00 hash searches/s, 0.00 non-hash searches/s
---
LOG
---
Log sequence number 4683173
Log flushed up to   4683173
Last checkpoint at  4683173
0 pending log writes, 0 pending chkp writes
18 log i/o's done, 0.00 log i/o's/second
----------------------
BUFFER POOL AND MEMORY
----------------------
Total memory allocated 137363456; in additional pool allocated 0
Dictionary memory allocated 58289
Buffer pool size   8192
Free buffers       7793
Database pages     398
Old database pages 0
Modified db pages  0
Pending reads 0
Pending writes: LRU 0, flush list 0, single page 0
Pages made young 0, not young 0
0.00 youngs/s, 0.00 non-youngs/s
Pages read 397, created 1, written 21
0.00 reads/s, 0.00 creates/s, 0.00 writes/s
No buffer pool page gets since the last printout
Pages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s
LRU len: 398, unzip_LRU len: 0
I/O sum[0]:cur[0], unzip sum[0]:cur[0]
--------------
ROW OPERATIONS
--------------
0 queries inside InnoDB, 0 queries in queue
1 read views open inside InnoDB
Main thread id 6572, state: waiting for server activity
Number of rows inserted 1, updated 1, deleted 0, read 12
0.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 0.00 reads/s
----------------------------
END OF INNODB MONITOR OUTPUT
============================
```





### InnoDB页结构

> InnoDB将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 16KB。一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。InnoDB有多种页，索引页，Undo页，Inode页，系统页，BloB页等。

![img](/../img/innodb页结构图.jpg)

#### mysql索引和页的关系？

B-tree结构可以显著减少定位记录时所经历的中间过程，从而加快存取速度，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。为了达到这个目的，磁盘按需读取，要求每次都会预读的长度一般为页的整数倍。而且数据库系统将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。并把B-tree中的m值设的非常大，就会让树的高度降低，有利于一次完全载入。

#### 磁盘块和索引

![](../img/B+%E6%A0%91%E7%A3%81%E7%9B%98%E5%9D%97.jpg)

如图所示是 `B+ Tree` 的数据结构。是由一个一个的磁盘块组成的树形结构，每个磁盘块由数据项和指针组成。

> 所有的数据都是存放在叶子节点，非叶子节点不存放数据。索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。

以磁盘块1为例，指针 P1 表示小于17的磁盘块，P2 表示在 17~35 之间的磁盘块，P3 则表示大于35的磁盘块。比如要查找数据项99，首先将磁盘块1 load 到内存中，发生 1 次 IO。接着通过二分查找发现 99 大于 35，所以找到了 P3 指针。通过P3 指针发生第二次 IO 将磁盘块4加载到内存。再通过二分查找发现大于87，通过 P3 指针发生了第三次 IO 将磁盘块11 加载到内存。最后再通过一次二分查找找到了数据项99。由此可见，如果一个几百万的数据查询只需要进行三次 IO 即可找到数据，那么整个效率将是非常高的。观察树的结构，发现查询需要经历几次 IO 是由树的高度来决定的，而树的高度又由磁盘块，数据项的大小决定的。磁盘块越大，数据项越小那么树的高度就越低。这也就是为什么索引字段要尽可能小的原因。

#### 为什么innodb表最大支持64TB?

innodb的页号是一个32bit int类型数值，一页大小默认为16KB，那么最多有2^32 * 16kb =  64TB

#### 页、磁盘块与扇区联系

* 概念
  * 扇区：磁盘的最小存储单位
  * 磁盘块：文件系统读写数据的最小单位
  * 页：内存的最小存储单位
* 联系
  * 一个磁盘块由连续几个（2^n）扇区组成
  * 页的大小为磁盘块大小的2^n倍
* 查看
  * 页大小查看： getconf PAGE_SIZE，常见为4K
  * 磁盘块大小查看：stat /boot/|grep 'IO Block'，常见为4K
  * 扇区大小查看：fdisk -l，常见为512Byte



## 高可用

两地三中心  两地 = 本地 + 异地 ，三中心 = 本地数据中心 + 本地备份数据中心 + 异地备份数据中心

主备数据中心之前一般有冷备 、 热备 、 双活三种备份方式。

冷备：在某一个时间节点上进行数据备份，周期性备份，只有主数据中心承担业务。

热备：备份数据中心实时备份，只有主数据中心承担业务。当主数据中心挂掉之后，流量自动切换到备份数据中心，业务无感知数据中心的变化。

双活： 备份数据中心实时备份，主数据中心承担大部分业务，备份数据中心也承担部分业务，双向互为备份，故障相互切换。

# 多版本并发控制

**MVCC最大的优点是读不加锁，读写不冲突。**



共享锁（共享读 也可以排他读）和排它锁  共享锁之间可以兼容 共享锁和排它锁不可以兼容 。   

多版本控制MVCC，读不用加锁，写加锁，读写不冲突（隐藏的ID，修改事务ID，删除事务ID，回滚点PT，读只能读去修改事务ID小于等于当前事务ID的版本并且删除事务版本为空或删除事务版本大于当前事务版本）

行锁设计的目的是为了提升的并发性能，而多版本控制（MVCC）是为了得到更高的并发性能。



Select时只能查询到小于等于当前事务版本号的行，并且当删除时间为空或者大于当前版本号的行。

Insert为新插入的行保存当前系统版本号为最新的行的版本号。

Update为插入一行新纪录，保存当前系统版本号为新记录行版本号，同时保存当前系统版本号为原来行的删除记录的版本号。

Delete为删除的每一个行保存当前系统版本号为删除的每一行的行版本号。



隐藏的三列： 1. 隐藏的ID（ID） 2. 记录执行事务的事务ID（DB_TRX_ID） 3.指向回滚点的回滚指针（DB_ROLL_PT）

例子1：A事务进行读，同时B事务对A读的同一行进行了修改，但是A事务只能看到小于等于自身事务ID的版本，看不到大于A事务ID的版本（即B事务修改数据增加了版本行，事务ID增加）。B事务提交了，A事务再次读，也读取不到B事务修改的数据。

例子2：A事务进行读，同时B事务进行删除，删除也是修改的一种，会增加版本，修改删除事务ID为当前事务，这个时候B提交了， A事务可以看到数据被删除了吗？

A只能看到小于等于A当前事务的事务ID的版本的数据，等于的情况（A事务自身修改的数据） 并且 删除事务ID 大于当前事务ID的版本（这个是不是幻读了？）。



多版本控制实验：

| 时间线 | 事务A                                                        | 结果            | 事务B                                                        | 结果               |
| ------ | ------------------------------------------------------------ | --------------- | ------------------------------------------------------------ | ------------------ |
|        | SELECT * from person where id = 1;                           | 1	tom@qq.com |                                                              |                    |
|        | set autocommit=off;<br/>START TRANSACTION;<br/>UPDATE person set email = "Jhon@foxmail.com" where id = 1; | 受影响的行: 1   |                                                              |                    |
|        | SELECT TRX_ID FROM INFORMATION_SCHEMA.INNODB_TRX  WHERE TRX_MYSQL_THREAD_ID = CONNECTION_ID(); | 87337           |                                                              |                    |
|        |                                                              |                 | set autocommit=off;<br/>start TRANSACTION;<br/>select * from person where id = 1; | 1	tom@qq.com    |
|        |                                                              |                 | SELECT TRX_ID FROM INFORMATION_SCHEMA.INNODB_TRX  WHERE TRX_MYSQL_THREAD_ID = CONNECTION_ID(); | TRX_ID 87338       |
|        | commit;                                                      | [SQL]commit;    |                                                              |                    |
|        |                                                              |                 | select * from person where id = 1;<br/>COMMIT;               | 1	tom@qq.com    |
|        |                                                              |                 | set autocommit=off;<br/>start TRANSACTION;<br/>select * from person where id = 1;<br/>COMMIT; | 1 Jhon@foxmail.com |

通过上面的实验可以看出,A事务先启动，进行了id=1行数据的修改，事务B这个时候启动，B的事务ID在A事务ID增加了1为87338，实验显示B事务确实看不到A事务的修改，即使A事务提交了数据之后B事务仍然看不到A的修改，这是为什么呢？ 

多版本控制下，复制的版本之后，未提交版本之前，该版本是锁定的吗？ 修改的事务ID或者删除的事务ID是什么时候写入的？ 为什么上面的B事务不能看到A事务的修改的数据。

猜测： 如果开启了多版本控制，复制的版本（未提交）应该是锁定的，即使像B这样的读事务也看不到。

至于A事务对复制的版本什么时候写入 修改事务ID和删除事务ID 这并不重要，确定的是一定会在事务提交之前写入事务ID到版本。

那么开启了多版本控制吗？

SELECT  VERSION(); -- 5.6.38

非锁定的列、版本

layout:     post
title:	MYSQL专题
subtitle: 	Innodb锁机制
date:       2019-12-23
author:     chuangkel
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 数据库
---

# Innodb锁机制

数据库使用锁是为了支持更好的并发，提供数据的完整性和一致性。InnoDB是一个支持行锁的存储引擎，锁的类型有：共享锁（S）、排他锁（X）、意向共享（IS）、意向排他（IX）。为了提供更好的并发，InnoDB提供了非锁定读：不需要等待访问行上的锁释放，读取行的一个快照。该方法是通过InnoDB的一个特性：MVCC来实现的。

**InnoDB有三种行锁的算法：**

1，Record Lock：单个行记录上的锁。

2，Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况 。

3，Next-Key Lock：1+2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

### 例子：

```mysql
create table t(a int,key idx_a(a))engine =innodb;
insert into t values(1),(3),(5),(8),(11);
select * from t;
-- Section A
start transaction;
select * from t where a = 8 for update;
-- Section B
begin;
select * from t;
insert into t values(2);
insert into t values(4);
insert into t values(6);
-- [SQL]
-- insert into t values(6);
-- [Err] 1205 - Lock wait timeout exceeded; try restarting transaction
```

- 为什么要针对查询操作锁定一个范围？而不是锁定一个行？
- 这个范围包含左右边界值吗？ 为什么？
  - 锁定是包含左边的值，不包含右边的值。因为隐藏的ROWID是递增的。例如上面的例子：对行 a=8 ，其实是a=8的前一个键值到后一个键值，[5,11)，不包含后一个键值的一个范围，5,6,7,9,10这些值的插入将被阻塞住。
- 幻读是怎么解决的？
  - 加锁： 间隙锁（不包含边界）和next-key locking锁（包含左边界不包含有边界）

**问题：**

**为什么section B上面的插入语句会出现锁等待的情况**？InnoDB是行锁，在section A里面锁住了a=8的行，其他应该不受影响。why？

**分析：**

因为InnoDB对于行的查询都是采用了Next-Key Lock的算法，锁定的不是单个值，而是一个范围（GAP）。上面索引值有1，3，5，8，11，其记录的GAP的区间如下：是一个**左开右闭**的空间（原因是默认主键的有序自增的特性，结合后面的例子说明）

（-∞,1]，(1,3]，(3,5]，(5,8]，(8,11]，(11,+∞）

特别需要注意的是，InnoDB存储引擎还会对辅助索引下一个键值加上gap lock。如上面分析，那就可以解释了。

```
root@localhost : test 10:56:29>select * from t where a = 8 for update;
+------+
| a    |
+------+
|    8 |
+------+
row in set (0.00 sec)
```

该SQL语句锁定的范围是（5,8]，下个下个键值范围是（8,11]，所以插入5~11之间的值的时候都会被锁定，要求等待。即：插入5，6，7，8，9，10 会被锁住。插入非这个范围内的值都正常。

因为例子里没有主键，所以要用隐藏的ROWID来代替，数据根据Rowid进行排序。而Rowid是有一定顺序的（自增），所以其中11可以被写入，5不能被写入，不清楚的可以再看一个有主键的例子：

### 有主键的例子

```mysql
create table t(id int,name varchar(10),key idx_id(id),primary key(name))engine =innodb;
insert into t values(1,'a'),(3,'c'),(5,'e'),(8,'g'),(11,'j');  
select @@global.tx_isolation, @@tx_isolation;   
select * from t;
-- sectiion A
start transaction;   
delete from t where id=8;

-- section B
select @@global.tx_isolation, @@tx_isolation;
start transaction; 
select * from t;
-- 
insert into t(id,name) values(6,'f');
insert into t(id,name) values(5,'e1');
insert into t(id,name) values(7,'h');
insert into t(id,name) values(8,'gg');
insert into t(id,name) values(9,'k');
insert into t(id,name) values(10,'p');
insert into t(id,name) values(11,'iz');
-- 以上都被阻塞住了
insert into t(id,name) values(5,'cz');
insert into t(id,name) values(11,'ja');
-- 说明了 gap lock 和 next-key locking锁?
```



**分析：**因为会话1已经对id=8的记录加了一个X锁，由于是RR隔离级别，INNODB要防止幻读需要加GAP锁：即id=5（8的左边），id=11（8的右边）之间需要加间隙锁（GAP）。这样[5,e]和[8,g]，[8,g]和[11,j]之间的数据都要被锁。上面测试已经验证了这一点，根据索引的有序性，数据按照主键（name）排序，后面写入的[5,cz]（[5,e]的左边）和[11,ja]（[11,j]的右边）不属于上面的范围从而可以写入。

另外一种情况，把name主键去掉会是怎么样的情况？有兴趣的同学可以测试一下。



### **继续：**插入超时失败后，会怎么样？

超时时间的参数：innodb_lock_wait_timeout ，默认是50秒。
超时是否回滚参数：innodb_rollback_on_timeout 默认是OFF。

```mysql
create table t(a int,key idx_a(a))engine =innodb;
insert into t values(1),(3),(5),(8),(11);
-- section A
start transaction;
select * from t where a = 8 for update;
-- section B
start transaction;
insert into t values(12);
insert into t values(10);
select * from t;
-- [SQL]
-- insert into t values(10);
-- [Err] 1205 - Lock wait timeout exceeded; try restarting transaction
```

经过测试，不会回滚超时引发的异常，当参数innodb_rollback_on_timeout 设置成ON时，则可以回滚，会把插进去的12回滚掉。

下图中，innodb_rollback_on_timeout 为ON，12被回滚掉了。

![1570521891245](/..\img\1570521891245.png)

默认情况下，InnoDB存储引擎不会回滚超时引发的异常，除死锁外。

既然InnoDB有三种算法，那Record Lock什么时候用？还是用上面的列子，把辅助索引改成唯一属性的索引。

### Record Lock实践

```mysql
create table t(a int primary key)engine =innodb;
insert into t values(1),(3),(5),(8),(11);
select * from t;
-- section A
start transaction;
select * from t where a = 8 for update;
-- section B
start transaction;
insert into t values(6);
insert into t values(7);
insert into t values(9);
insert into t values(10);
```

**问题：**

为什么section B上面的插入语句可以正常，和测试一不一样？

**分析：**

因为InnoDB对于行的查询都是采用了Next-Key Lock的算法，锁定的不是单个值，而是一个范围，按照这个方法是会和第一次测试结果一样。**但是，当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。**

注意：通过主键或则唯一索引来锁定不存在的值，也会产生GAP锁定。即

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `name` varchar(10) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
insert into t values(1,'a'),(3,'c'),(5,'e'),(8,'g'),(11,'j');   
-- section A
start transaction;
select * from t where id = 15 for update;
-- section B
insert into t(id,name) values(10,'k');
-- 以上可以执行
insert into t(id,name) values(12,'k');
insert into t(id,name) values(16,'kxx');
insert into t(id,name) values(160,'kxx');
-- 以上阻塞
```

如何让测试一不阻塞？可以显式的关闭Gap Lock：

1：把事务隔离级别改成：Read Committed，提交读、不可重复读。SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;

2：修改参数：innodb_locks_unsafe_for_binlog 设置为1。



# 锁

**引言**

1. 行锁是加在索引上的吗？
3. 行锁是怎么实现的？
3. 有什么可以查看事务加锁的情况？
4. record lock 、gap lock 、next-key lock 算法的用途和区别？
5. 什么情况下会锁一张表？锁全表的方式？如何避免锁全表？

**分析**

### 1. 行锁是加在索引上的吗？ 

   查看一下有主键和没有主键的执行计划的差别：

```mysql
-- 没有主键的表结构
CREATE TABLE `t1` (
  `id` int(11) NOT NULL,
  `name` varchar(10) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
-- 结果扫描了6行，全表扫描了。
```

![1570612398476](/..\img\1570612398476.png)

```mysql
-- 有主键的表结构
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `name` varchar(10) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
-- 可以看到只扫描了一行。查询对行加排他锁。
```

![1570612085370](/..\img\1570612085370.png)

**结论：**

扫描的行数和有没有索引是有关系的，若查询条件能走索引，这会通过索引查找。反之全表扫描。这并不能说明行锁是加在索引上的，该怎么证明呢？

设计实验证明： 分两种情况，有索引和没索引实验。

**有索引：**

```mysql
-- section A
BEGIN;
SELECT * from t WHERE id = 3 for UPDATE;
-- section B
BEGIN;
SELECT * from t WHERE id = 5 for UPDATE;
```

Section A 结果：

![1570613014245](/..\img\1570613014245.png)

Section B结果：

![1570612982100](/..\img\1570612982100.png)

**没有索引：**

```mysql
-- section A
BEGIN;
SELECT * from t1 WHERE id = 3 for UPDATE;
-- section B
BEGIN;
SELECT * from t1 WHERE id = 5 for UPDATE;
```

Section A 结果：

![1570613014245](/../img/1570613014245.png)

Section B 结果：

![1570613166117](/../img/1570613166117.png)

**结果分析：加索引情况for update对行加了排他锁，但是各个行锁直接兼容而不会影响。没有加索引情况下for update对表加了表排他锁，所以第二个事务执行的时候被第一个事务阻塞住了，需等第一个事务释放表排他锁之后才能继续执行。这足以说明添加索引的重要性，可以降低加锁的粒度，减少资源占用，提高并发量。 提个问题： 该实验中可以使用共享锁来实验吗，即改成lock in share mode,答案是否定的，因为两个共享锁是兼容的**

注意： 实验的条件是查询条件需走索引和不走索引来控制的。

***由此得出：行锁是加在索引上的。因为没有索引情况下没用使用行锁而使用了表锁。***

### 2. 行锁是怎么实现的？

行锁是基于索引来实现的，或者说是加在索引上的，这一点和oracle是不同的。如果表没有建立索引，primary key、unique key或者key普通索引，则不能使用行锁而使用表锁。

在对行加共享锁之前先对表加意向共享锁。

在对行加排它锁之前先对表加意向排它锁。

意向锁是为了防止行锁和表锁的加锁过程中全表扫描，加上意向锁提供后来的事务判断。

若事务B请求行级排它锁（X）即请求意向排它锁（IX），发现表被事务A加了意向排它锁（IX），由于意向排它锁（IX）可以兼容，事务B加上意向排它锁（IX）之后再对具体的行加行级排它锁（X）。

若事务B请求表级排它锁（X），发现表被事务A加了意向排它锁（IX），由于意向排它锁（IX）和表级锁（X）不可以兼容， 事务B必须等待事务A的意向排它锁（IX）的释放。

若事务B请求行级共享锁（S）即请求意向共享锁（IS），发现表被事务A加了意向排它锁（IX），由于意向共享锁（IS）和意向排它锁（IX）可以兼容，事务B可以获取意向共享锁（IS)，然后再请求行级共享锁（S)，设计实验验证一下。

若事务B请求表级共享锁（S），发现表被事务A加了意向排它锁（IX），由于表级共享锁（S）和意向排它锁（IX）不可以兼容， 事务B必须等待事务A的意向排它锁（IX）的释放，才能获取表级共享锁。

| 请求事务/是否兼容/当前事务 | S      | X      | IS     | IX     |
| -------------------------- | ------ | ------ | ------ | ------ |
| S                          | 兼容   | 不兼容 | 兼容   | 不兼容 |
| X                          | 不兼容 | 不兼容 | 不兼容 | 不兼容 |
| IS                         | 兼容   | 不兼容 | 兼容   | 兼容   |
| IX                         | 不兼容 | 不兼容 | 兼容   | 兼容   |

注意： S和X锁有表级和行级。

### 3. 有什么可以查看事务加锁的情况？

在没有索引情况下两个事务阻塞了，如下msyql语句：

```mysql
-- section A
BEGIN;
SELECT * from t1 WHERE id = 3 for UPDATE;
-- section B
BEGIN;
SELECT * from t1 WHERE id = 5 for UPDATE;
```



![1570622046837](/..\img\1570622046837.png)

没有索引会锁全表，为啥lock_page、lock_rec和lock_date不为null呢？

若没有主键或者唯一索引的话，innodb引擎会生成隐藏的聚簇索引gen_clust_index，所有的索引上都会加上锁，相当于加了表锁。求论证。

![1570622288286](/..\img\1570622288286.png)





### 4. record lock 、gap lock 、next-key lock 算法的用途和区别？

锁都是加在索引上的，若没有创建任何索引，会创建隐含的索引，锁会加在隐含的索引上，那么加在隐含索引上和显式定义的索引索引上有什么区别？

record lock用来加在确定的行索引上的

record lock用来加在确定的行索引上的

gap lock（间隙锁） 加在没有边界的索引范围上，用于解决在可重复读隔离级别下的幻读问题（phantom problem）。

next-key lock加在包含边界的索引范围上。

gap lock 和 next-key lock的区别：

不包含范围边界和包含范围边界的区别。

### 5. 什么情况下会锁一张表？锁全表的方式？如何避免锁全表？

1. where条件不走索引会锁全表。
2. 没有where条件会锁全表，实验一下，好像是不对的。
3. lock table t read、lock table t write 来锁全表。

### 6. 锁在msyql中扮演什么角色？即起什么作用。

采用不同的锁实现了不同事务隔离级别的要求。每个事务是一个线程，未提交读没有加锁。提交读有不可重复读的问题，是通过record lock锁来解决的。幻读问题是根据gap lock 和 next key locking来解决。




## 正文

### 锁粒度

> 锁策略：在锁的开销和数据安全性之间寻求平衡。常见两种锁策略，表锁(table lock)和行锁(row lock)。

### 表锁(table lock)

> 表锁(table lock)是mysql中最基本的锁策略，也是开销最小的锁策略。一个用户在对表进行写操作（增加，删除，修改）前，需要先获取写锁，写锁会阻塞其他写锁和读锁。写锁的优先级比读锁的优先级高，写锁可以插入到锁队列中读锁的前面。

```mysql
lock table t read; -- 加表级读锁
lock table t write; -- 加表级写锁
UNLOCK tables -- 释放锁
```

### 行锁(row lock)

> 行锁(row lock)只在存储引擎层实现。服务器层完全不了解行锁的实现。InnoDB和XtraDB实现了行级锁。

### 页面锁

> 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

## 共享锁、排他锁与意向锁

共享锁与独占锁均用于事务当中，随事务的结束而解除。

**共享锁（share lock，S锁）**

又称读锁，读取操作创建的锁。

一旦上锁，任何事务（包括当前事务）无法对其修改，其他事务可以并发读取数据，也可在对此数据再加共享锁

语法：SELECT ... LOCK IN SHARE MODE （select默认的是共享锁，不写）

**排他锁（exclusive lock，X锁）**

又称写锁，如果事务对数据A加上排他锁后，则其他事务不可并发读取数据，也不能再对A加任何类型的锁。获准排他锁的事务既能读数据，又能修改数据。

语法：SELECT ... FOR UPDATE

**意向锁（IS锁，IX锁）**

**InnoDB所用的**表级锁，其设计目的主要是为了在一个事务中揭示下一步将要被请求的锁的类型。

InnoDB中的两个表锁：

意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁

意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。

**意向锁是InnoDB自动加的，不需要用户干预。**

#### 意向锁的分类：

意向共享锁，事务想要给数据库某些行加共享锁，需要先获取意向共享锁
意向互斥锁，事务想要给数据库某些行加互斥锁，需要先获取意向互斥锁
意向锁是表锁，提高加表锁和行锁之间冲突时的判断效率。

**问题：为什么需要意向锁？**
主要为了实现多粒度锁。

LOCK TABLE table_name READ；用共享锁锁住整个表
LOCK TABLE table_name WRITE；用互斥锁锁住整个表
**分析：**假设没有意向锁，事务A使用行锁锁住其中一行，事务B申请表的互斥锁，然后修改整个表，行锁和表锁就会发生冲突，要解决冲突，事务B需要等待事务A锁住的行锁释放，但是事务B并不知道事务A锁住的是哪一行，所以事务B会遍历数据库每一行判断是否有行锁，这是一个非常耗时的过程。

为了解决上述问题引入意向锁，事务A在加行锁前，先需要给表加上对应的意向锁，这样如果事务B来获取表锁，需要先判断表上是否有意向锁，如果有意向锁，则阻塞，等待事务A的锁释放。**提高加表锁和行锁之间冲突时的判断效率。**

意向锁和表锁之间兼容关系：

|           | 意向共享锁(IS) | 意向互斥锁(IX) |
| --------- | -------------- | -------------- |
| 共享锁(S) | 兼容           | 互斥           |
| 互斥锁(X) | 互斥           | 互斥           |

## 元数据锁

元数据锁属于表锁范畴，元数据即数据字典信息

MDL 不需要显式使用，在访问一个表的时候会被自动加上
MDL的作用是维护数据的一致性
问题： 为什么需要元数据锁
线程A查询数据库，线程B对表结构进行变更，比如说删除某一列，修改列名，那么查询结果和数据库表结构对应不上，这就冲突了

MDL锁不需要显示使用，在访问表结构的时候被自动加上
对表做增删改查操作，加MDL读锁，对表结构变更的时候加MDL写锁
兼容性和正常行锁读写锁保持相同，读读兼容，读写，写写不兼容
MDL锁可能带来的问题：

事务A查询表记录，事务B给表加字段，事务C查询表记录

事务A会给表加MDL读锁，事务B会加MDL写锁，事务C给表加读锁

读写锁不兼容，事务B必须等待事务A提交结束才能继续执行，事务C虽然是读锁，读锁之间相互兼容，但是由于事务B的存在，也会阻塞，如果这时查询请求很频繁，会造成大量请求失败。

## 乐观锁和悲观锁

1. 什么是乐观锁和悲观锁？

## 死锁

> 死锁是两个或者多个事务在同一资源上的相互占用，并请求锁定对方占用的资源。

#### 参数设置：

innodb_rollback_on_timeout 这个参数关闭或不存在的话遇到超时只回滚事务最后一个Query，打开的话事务遇到超时就回滚整个事务。innodb_rollback_on_timeout  = OFF 不会回滚超时引发的异常事务 死锁的除外；innodb_rollback_on_timeout = ON 则会。 

```shell
[mysqld] #只能在[mysqld]下面添加 否则不生效
innodb_rollback_on_timeout=1
# 配置文件中设置，重启生效
# windwos设置之后重启msyql
# net stop mysql
# net start mysql
```

```mysql
show VARIABLES like 'innodb_rollback_on_timeout' -- 查看设置
```

#### 死锁实践

事务一开启，执行前半截；然后事务二执行就可以发现资源等待情况，如果事务一继续执行后半截的话，就会发现死锁。mysql会自动检测死锁，当发生死锁时，会回滚最少持有行级锁的事务。

```mysql
-- 事务一
set autocommit = 0;
START TRANSACTION;
UPDATE stockprice set `close` = 1 where stock_id = 5 and date = '2019-10-04';
UPDATE stockprice set `close` = 1 where stock_id = 3 and date = '2019-10-02';
UPDATE stockprice set `close` = 1 where stock_id = 4 and date = '2019-10-03';
COMMIT;
-- 事务二
set autocommit = 0;
START TRANSACTION;
UPDATE stockprice set `close` = 2 where stock_id = 4 and date = '2019-10-03';
UPDATE stockprice set `close` = 2 where stock_id = 3 and date = '2019-10-02';
COMMIT;
```

等待超时之后的结果：

```
[SQL]
UPDATE stockprice set `close` = 2 where stock_id = 4 and date = '2019-10-03';
[Err] 1205 - Lock wait timeout exceeded; try restarting transaction
```

死锁时回滚最小持有行的事务



layout:     post
title:	MYSQL专题
subtitle: 	索引
date:       2019-12-18
author:     chuangkel
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 数据库
---

# 索引

**引言**

1. 索引是一种数据结构，根据索引可以快速定位到所要的数据。而索引自身也是数据，其存放在哪里？多个索引如何存放？如何将存放的数据转换成内存中的数据结构以便查找？ 索引文件是怎么样的结构？
2. primary key，key，unique key，index有什么区别？

**分析：**

### 1. 索引是一种数据结构，根据索引可以快速定位到所要的数据。而索引自身也是数据，其存放在哪里？多个索引如何存放？如何将存放的数据转换成内存中的数据结构以便查找？ 索引文件是怎么样的结构？



### 2. primary key，key，unique key，index有什么区别？

primary key 主键，是聚簇索引，索引和数据存储在一起。

unique key 被其修饰的列不可以重复插入，保证了其唯一性。

key 被其修饰的列可以重复插入。主要有两个作用：1. 约束数据的完整性 2. 辅助查询的作用，比如 primary key，unique key，foreign key。

index 被其修饰的列可以重复插入。主要作用是辅助查询，比如 primary key，unique key ，key普通索引。

不管是key 还是index 区别不大，最后生成的建表信息都会是key，如下：

```mysql
CREATE TABLE `t4` (
  `id` int(11) NOT NULL,
  `name` varchar(10) DEFAULT NULL,
  KEY `key_id` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

同时，key 索引（普通索引）：加锁也可能会走普通索引的，不信可以试验一下。





## 数据库优化具备的基础知识

> explain 只能解释select查询语句。select 查看查询语句的执行计划

### 执行计划实践

```mysql
CREATE TABLE `user_info` (
  `id`   BIGINT(20)  NOT NULL AUTO_INCREMENT,
  `name` VARCHAR(50) NOT NULL DEFAULT '',
  `age`  INT(11)              DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `name_index` (`name`)
)
  ENGINE = InnoDB
  DEFAULT CHARSET = utf8;

INSERT INTO user_info (name, age) VALUES ('xys', 20);
INSERT INTO user_info (name, age) VALUES ('a', 21);
INSERT INTO user_info (name, age) VALUES ('b', 23);
INSERT INTO user_info (name, age) VALUES ('c', 50);
INSERT INTO user_info (name, age) VALUES ('d', 15);
INSERT INTO user_info (name, age) VALUES ('e', 20);
INSERT INTO user_info (name, age) VALUES ('f', 21);
INSERT INTO user_info (name, age) VALUES ('g', 23);
INSERT INTO user_info (name, age) VALUES ('h', 50);
INSERT INTO user_info (name, age) VALUES ('i', 15);
```



#### explain返回的字段：

* id  每一个select都会返回一个id
* select_type
  * simple ，表示此查询不包含 UNION 查询或子查询
  * primary，表示此查询是最外层的查询
  * union，
  * dependent union，
  * ...
* table
* partitions
* type 访问类型
  * null ：eg. select max() from ...
  
  * system/const ：where 后面=是常量
  
  * eq_ref 多表查询时，根据非唯一空索引进行查询
  
  * ref 多表查询时，根据非唯一非空索引进行查询
  
  * range 在索引上进行范围查找：当=,< ,> ,<=,>=,<>,<=>,in,between,is null
  
    * <=> 安全比较运算符，用来做 NULL 值的关系运算SELECT 1 <=> NULL, !(1 <=> NULL);// 结果0,1
  
    * != 和 not in 不走索引
  
    * @用来标识用户变量，@@用来标识系统变量 
  
  * index 遍历索引树
  
  * all 全表扫描
  
  * 比较：ALL < index < range ~ index_merge < ref < eq_ref < const < system<null
* possible_keys 查询中可能使用的索引。possible_keys为null，说明没有where条件时优化器无法通过索引检索数据。
* key 实际中使用到的索引
* key_len 实际索引长度
* rows此次查询所需读取的行数。越小越好
* extra 
  * Using index 在查询树中就可查询到数据，没有操作数据表。
  * Using index condition 需要回表。
  * Using temporary使用了临时表，一般出现于join,排序，分组的情况。
  * Using filesort 没有使用索引排序，进行了额外的排序。可以对排序字段加索引。
    * 下面的例子：dim_id有索引（主键），dim_name无索引
      * EXPLAIN select * from hg_tdimension order by dim_id; // type:index,extra:null
      * EXPLAIN select * from hg_tdimension order by dim_name; // type:all,extra:Using filesort



### 数据库优化的思路

* 加索引
* 语句优化
* 分库分表

### 索引类型

> B+Tree结构都可以用在MyISAM和InnoDB上

例子：主键id,二级索引plname

| id   | plname | ranking |
| :--- | :----- | :------ |
| 15   | C      | 2       |
| 16   | Java   | 1       |
| 18   | Php    | 6       |
| 23   | C#     | 5       |
| 26   | C++    | 3       |
| 29   | Ada    | 17      |
| 50   | Go     | 12      |
| 52   | Lisp   | 15      |

- 聚簇索引(主键索引) 索引数据和存储数据是一起的。

  > InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用"where id = xxx"这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树中再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。
  >
  > 每个表只能有一个聚簇索引。聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。聚簇索引要比非聚簇索引查询效率高很多。聚集索引这种主+辅索引的好处是，当发生数据行移动或者页分裂时，辅助索引树不需要更新，因为辅助索引树存储的是主索引的主键关键字，而不是数据具体的物理地址。

![img](/../img/聚簇索引.png)

- 非聚簇索引 索引数据和存储数据是分离的。

  > MyISAM的是非聚簇索引，B+Tree的叶子节点上的data，并不是数据本身，而是数据存放的地址，主索引和辅助索引没啥区别，只是主索引中的key一定得是唯一的。主索引和辅助索引的两棵B+树看上去没什么不同，节点的结构完全一致只是存储的内容不同而已，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，主索引和辅助索引的两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。
  >
  > InnoDB的数据文件本身就是索引文件，B+Tree的叶子节点上的data就是数据本身，这是聚簇索引。(所以聚簇索引的主键不能过长)

![img](/../img/聚簇索引和非聚簇索引.png)

- 辅助索引（二级索引）
  - 普通索引
  - 唯一索引
  - 前缀索引。原则：降低重复的索引值。索引值重复性越低，查询效率也就越高，节省空间。
    - alter table test add index(name(9)); -- 以前9位字符构建索引（注：实践）

![img](/../img/辅助索引.png)





#### 什么是索引覆盖？

> 覆盖索引（covering index）指一个查询语句的执行只需要从辅助索引中就可以得到查询记录，而不需要根据辅助索引得到的主键去查询聚集索引中的记录，也称索引覆盖。
>
> ```mysql
> explain select sql_no_cache count(staff_id) from t1 --会全表扫描
> alter table t1 add key(staff_id); -- 添加之后上面的sql会走索引 staff_id.前提条件是，查询返回的字段数足够少.
> -------------------------
> --未加索引之前，会回表查询，extra执行计划列：using index condition (inventory_id是二级索引，实践：inventory_id是主键的情况 )
> explain select sql_no_cache rental_date from t1 where inventory_id<80000
> --加索引，extra执行计划列：using index
> alter table t1 add key(inventory_id,rental_date);
> ```

#### 覆盖索引的优势？

* select的列在索引中
* where条件中要包含索引列或复合索引的前导列

```mysql
EXPLAIN select task_id,phase,biz_id,trigger_time from xxx_table where task_id = '40001000000000061743' and phase = 0
 and biz_id = 'xxx';
//下面是覆盖索引 
EXPLAIN select task_id,phase,biz_id from xxx_table where task_id = '40001000000000061743' and phase = 0
 and biz_id = 'xxx';
 //
   PRIMARY KEY (`slice_id`),
  UNIQUE KEY `uk_ti_bi` (`task_id`,`phase`,`biz_id`),
  KEY `idx_xxx_sta_tri` (`task_id`,`status`,`phase`,`trigger_time`)
```

结果如下

![1585900422284](./..\img\1585900422284.png)

### 为什么加索引？

> 索引是针对查询，索引是B树或者B+树的数据结构。两大好处：
>
> * 根据索引返回只需要的数据
> * 从索引中直接返回数据

### 怎么加索引？



#### 扩展：

> SQL_NO_CACHE 使查询不走缓存 Select SQL_NO_CACHE * from geek where c=3 order by b limit 1;

* limit 5 //相当于limit 0 5，返回第1到5条记录
* limit 10,15 //返回第11-15条记录





单表数据



```mysql
-- 表结构 
CREATE TABLE `bpthold` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `business_date` int(11) NOT NULL,
  `portid` int(11) NOT NULL,
  `portname` varchar(128) COLLATE gbk_bin NOT NULL,
  `intercode` int(11) NOT NULL,
  `stockcode` varchar(32) COLLATE gbk_bin NOT NULL,
  `stockname` varchar(128) COLLATE gbk_bin NOT NULL,
  `holdingamount` decimal(20,4) NOT NULL,
  `untransferedinvest` decimal(18,2) NOT NULL,
  `position_market_value` decimal(18,2) NOT NULL,
  `todayprofit` decimal(18,2) NOT NULL,
  `assetproportion` decimal(15,8) NOT NULL,
  `risefallratio` decimal(15,8) NOT NULL,
  `net_buy_amount` decimal(20,4) NOT NULL,
  `assetproportion2` decimal(15,8) NOT NULL,
  `numberproportion` decimal(15,8) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=26353148 DEFAULT CHARSET=gbk COLLATE=gbk_bin;

-- 统计大小
SELECT (`DATA_LENGTH`+ `INDEX_LENGTH`)/1024/1024  as `table_data_size`  from `TABLES` WHERE TABLE_NAME ='bpthold' and TABLE_SCHEMA='demo';

select count(*) from bp_thold; -- 耗时48.719s

```

单位M（4534.0M 约4G)，一共26353148条数据（2000W级别）

![1583227620231](D:\ali\yoga-markdown\yoga\md图片\1583227620231.png)





select * from abc 
EXPLAIN select * from abc where a>1 and b = 2 and c = 3;
EXPLAIN select * from abc where a=1 and b > 1 and c = 3;
EXPLAIN select * from abc where a=1 and b = 2 and c = 3;
EXPLAIN select * from abc where  b = 2 and c = 3;
EXPLAIN select * from abc where a > 1  ;
EXPLAIN select * from abc where a >= 1  ;





EXPLAIN select * from abcd where a>1 and b = 2 and c = 3;
EXPLAIN select * from abcd where a=1 and b > 1 and c = 3;
EXPLAIN select * from abcd where a=1 and b = 2 and c = 3;
EXPLAIN select * from abcd where  b = 2 and c = 3;
EXPLAIN select * from abcd where a > 1  ;
EXPLAIN select * from abcd where a >= 1  ;



# 事务管理机制

**引言**

1. 脏页和脏数据的区别？

2. 哪些情况会导致脏页刷回磁盘呢？

   

**分析**

### 1. 脏页和脏数据的区别？

脏页：是磁盘和数据库数据不一致引起的。为了提高性能，数据库的读写都是操作从磁盘加载到内存的那部分数据，所有的操作早已记录到了redo log日志持久化了，然后会在必要的时刻写回到磁盘。因为同步到磁盘是异步的，这就引起了内存数据和磁盘数据的不一致，数据不一致的页即脏页。不过不用担心这个问题，脏页迟早会刷回到磁盘去，如果掉电或者宕机，则根据redo log日志来恢复丢失的脏数据。

脏数据：在未提交读事务隔离级别下，A事务读到的B事务未提交的数据为脏数据。

### 2. 哪些情况会导致脏页刷回磁盘呢？

缓冲池不够用时，根据LRU算法最近最少使用原则，如果该页时脏页，会将脏页最新版本刷回磁盘。

redo log日志不可用时，会将所有脏页刷回磁盘。redo log并不是无限大的，而是一个循环的存储结构，当redo log大到一定时，可能会存在不可用情况，会将脏页刷回磁盘。

### 3. Checkpoint的作用？




### 事务特性

> ACID事务四大特性：原子性（atomicity)、一致性（consistency)、隔离性（isolation)、和持久性（durability)。

* 原子性（atomicity)：一个事务不可再分割，要么全部执行，要么不执行，不存在中间状态。
* 一致性（consistency)：业务的一致性，如A向B转账，事务执行前后，AB总的金额是一致的。数据库一致性，事务不会影响数据库的一致性，如外键约束，唯一索引，check约束和触发器设置，事务执行前后一致。
* 隔离性（isolation)：多个事务之间并发操作数据库，事务之间隔离。事务最复杂的问题都是有隔离性引起的，如事务的隔离级别。
* 持久性（durability) ：数据持久化的数据库中。

### 事务隔离级别有哪四种？

* 未提交读（RU Read Uncommitted）：允许脏读。事务A未提交之前，事务B读取事务A操作数据库的数据。
* 提交读（RC Read Committed）：允许不可重复读，解决脏读。
* 可重复读(RR Read Repeated )：允许幻读，解决不可重复读。innodb_locks_unsafe_for_binlog开启的条件下（InnoDb的多版本并发控制），可以解决幻读问题。(可重复读是mysql的默认事务隔离级别)
* 串行化读(RS Read Serializable）：在读取每一行中都加上行锁。解决了事务的脏读，不可重复读，幻读问题。但是成本较高。

### 事务隔离级别之间的三种问题？

* 脏读：A事务修改的数据未提交，B事务读取了A事务的未提交的数据。
* 不可重复读：针对的是同一条或固定几条数据。A事务两次对同一条或固定几条数据进行读取之间，B事务对A事务读取的数据进行了修改，导致A事务两次读取的数据不一致（修改的是行内数据）。
* 幻读：事务A两次范围查询之间，事务B在A查询的范围中进行增加或者删除某行或几行，导致A事务第二次读取和第一次读取的数据不一致。（增加或删除整行数据）

| 事务隔离级别\问题 | 脏读   | 不可重复读       | 幻读   | 加锁读 |
| ----------------- | ------ | ---------------- | ------ | ------ |
| 未提交读(R U)     | 允许   | 允许             | 允许   | no     |
| 提交读(R C)       | 不允许 | 允许             | 允许   | no     |
| 可重复读(R R)     | 不允许 | 不允许(默认情况) | 允许   | no     |
| 串行化读(R S)     | 不允许 | 不允许           | 不允许 | yes    |

> \* 这是通常情况下，不排除特殊情况。比如innodb_locks_unsafe_for_binlog开启的情况下，可重复读可以解决幻读的问题。

### innodb_locks_unsafe_for_binlog是什么？

> innodb_locks_unsafe_for_binlog默认为off





### 多版本并发控制 

> MVCC，Multi-Version Concurrency Control，多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问；在编程语言中实现事务内存。



| mysql中，A事务新增修改未提交，B事务进行读取A事务修改的表，只能读取到该表最新的版本的数据，待A事务提交之后方可读取A事务的数据。（默认隔离级别：可重复读）



```sql
SELECT @@tx_isolation; //查看数据库隔离级别，默认RR
```

<u>怎么加索引？</u>

* 查询概率比较高的表
* 从查询条件看，where条件十分频繁的列加唯一索引或组合索引。



<u>幻读产生的问题？</u>

A事务查询之后没有key_1,准备插入，但是在A事务查询之后插入之前，B事务插入了主键为key_1的行，则B事务会报Duplicate entry。注：瑜伽TA里面报过主键冲突Duplicate entry ,是通过重试来解决的。



<u>事务是怎么实现的？</u>

undo日志，进行事务的回滚



<u>默认事务隔离级别？</u>

可重复读，可重复读在开启next-key Lock锁算法的情况下，已经可以解决幻读的问题，达到了串行化的隔离级别。



<u>什么场景适合使用缓存呢？</u>

支付场景适合吗？ 下单支付，对支付的查询频率很低，不采用缓存应该问题不大。缓存是为了加速查询，即读多写少的情况，数据变动频率低的数据。降低数据库查询的压力。可以增加写数据库的能力？若查询都能在缓存查询到数据，那写数据时数据库加行锁时会更容易成功吗？

<u>数据库缓存一致性问题？</u>

场景分析： 场景元素 数据库 缓存 读多写少 读多写多  读少写多（不建议使用缓存）高并发 低并发

场景1：读多写少。先更新缓存再更新数据库，会出现不一致情况，更新数据库更容易失败。先更新数据库再更新缓存。

场景2：读少写多，先更新数据库，再更新缓存或删除缓存。

缓存过期时间本质是保证数据库缓存不一致问题

*先修改数据库，再修改缓存*，A线程查询缓存失效，从数据库查询数据，B线程修改数据，修改缓存，A线程刷新缓存，还是旧值。

*先修改数据库，再删除缓存*

*先删除缓存，再修改数据库*，A线程数据修改数据，删除缓存和修改数据库之间存在时间间隔，若有线程在此区间查询，在A线程修改数据库之前查询数据库，这个时候会覆盖之前删除的缓存，导致缓存还是旧值。

方案一：binlog日志解析，将数据库变动的消息放入MQ， 更新缓存，缺点延时，优点严格顺序更新。

方案二：tcc事务，在成功的方法，自定义侵入性方法更新缓存，和数据库事务绑定在一起。

为什么更新了数据库之后更新缓存会失败呢？程序的崩溃吗，那放在finally更新缓存，如果掉电或者宕机则无法保证一致性。

<u>电商秒杀场景适合用缓存吗？</u>