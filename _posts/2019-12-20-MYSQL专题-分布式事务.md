---
layout:     post
title:	MYSQL专题
subtitle: 	分布式事务
date:       2019-12-20
author:     chuangkel
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - java
---

# 分布式事务

## 分布式锁

> 单机系统中，并发场景读取公共资源时，使用同步或者加锁就可以实现。但是应用分布式了之后系统由以前的单进程多线程的程序变为了多进程多线程，这时使用以上的解决方案明显就不够了。
>
> 需满足锁的一般特征：
>
> - 高性能(加、解锁时高性能）
> - 可以使用阻塞锁与非阻塞锁
> - 不能出现死锁
> - 可用性(不能出现节点 down 掉后加锁失败)
>
> 任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。



###zookeeper方式实现

> 基于 ZK 的临时有序节点
>
> 客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

- 锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。
- 非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。
- 不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。
- 单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。

可以直接使用zookeeper第三方库`Curator`客户端，这个客户端中封装了一个可重入的锁服务。Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。

* 优点

有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题

* 缺点

性能上不如使用缓存实现分布式锁



### 使用缓存(redis)方式实现

> 基于 Redis 的 NX、EX参数（NX键存在不能set，不存在可以set；EX超时时间，自动删除key)
>
> ```redis
> redis 127.0.0.1:6379> SET KEY VALUE [EX seconds] [PX milliseconds] [NX|XX]
> ```
>
> - EX seconds - 设置指定的到期时间，单位为秒
> - PX milliseconds - 设置指定到期时间，单位为毫秒
> - NX - 只有设置键，如果它不存在
> - XX - 只有设置键，如果它已经存在
>
> ```redis
> redis 127.0.0.1:6379> SET yiibai redis EX 60 NX //如果该键不存在，将设置键yiibai，60秒到期
> OK //返回值：如果值被设置，回复OK；如果值不设置返回为null
> ```

缺点：

- 如在 key 超时之后业务并没有执行完毕但却自动释放锁了，这样就会导致并发问题
- 就算 Redis 是集群部署的，如果每个节点都只是 master 没有 slave，那么 master 宕机时该节点上的所有 key 在那一时刻都相当于是释放锁了，这样也会出现并发问题。就算是有 slave 节点，但如果在数据同步到 salve 之前 master 宕机也是会出现上面的问题

### 数据库方式实现

> 有两种方式（都是基于唯一索引）：基于数据库表、基于数据库排他锁

#### 基于数据库表增删

> 通过表中的记录的存在情况确定当前是否有锁存在

#### 基于数据库排他锁

> 通过数据库的排他锁来实现分布式锁。行级锁不一定靠谱，method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。

* 缺点
  * 当表数据量不大时，mysql会优化执行sql，不一定使用行锁而采用表锁，增加数据库连接从而撑爆数据库连接池。
  * 数据库时单点的，可以采用双向同步，遇故障切换。

## 分布式事务

> 分布式事务是指会涉及到操作多个数据库的事务。其实就是将对同一库事务的概念扩大到了对多个库的事务。目的是为了保证分布式系统中的数据一致性。分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果。（全部提交或全部回滚）

### TCC分布式事务

- 服务层分布式事务 TCC(Try-Confirm-Cancel)，基于服务层面的
- TCC事务管理器会使用try、confirm、cancel接口协调多个服务进行事务处理

![img](/../img/tcc事务.webp)

### 二阶提交协议（Two Phase Commitment Protocol）

> 二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。
>
> 在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。

#### 第一阶段：准备阶段(投票阶段)

> 事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。
>
> * 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。
>
> * 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）
>
> * 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。

#### 第二阶段：提交阶段（执行阶段）

> 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)
>
> * 当协调者节点从所有参与者节点获得的相应消息都为”同意”时
>
>   * 协调者节点向所有参与者节点发出”正式提交(commit)”的请求
>
>   * 参与者节点正式完成操作，并释放在整个事务期间内占用的资源
>
>   * 参与者节点向协调者节点发送”完成”消息
>
>   * 协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务
>
> * 当任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时
>
>   * 协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求
>   * 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源
>   * 参与者节点向协调者节点发送”回滚完成”消息
>   * 协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务

### 三阶提交协议Three Phase Commitment Protocol）

#### CanCommit阶段

* 事务询问：协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应

* 响应反馈：参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No

#### PreCommit阶段

* 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行
  * 发送预提交请求：协调者向参与者发送PreCommit请求，并进入Prepared阶段
  * 事务预提交：参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中
  * 响应反馈：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令
* 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断
  * 发送中断请求：协调者向所有参与者发送abort请求
  * 中断事务：参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断

#### DoCommit阶段

* 执行提交 
  * 发送提交请求：协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求
  * 事务提交：参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源
  * 响应反馈：事务提交完之后，向协调者发送Ack响应
  * 完成事务：协调者接收到所有参与者的ack响应之后，完成事务
* 中断事务：协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务
  * 发送中断请求：协调者向所有参与者发送abort请求
  * 事务回滚：参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源
  * 反馈结果：参与者完成事务回滚之后，向协调者发送ACK消息
  * 中断事务：协调者接收到参与者反馈的ACK消息之后，执行事务的中断

### 2PC和3PC的区别

> 相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit，而不会一直持有事务资源并处于阻塞状态，这种机制也会导致数据一致性问题。因为由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作，这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。

### Paxos算法

> 2PC和3PC都没有解决一致性问题，paxos解决了一致性问题